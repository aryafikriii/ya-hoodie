{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "import torch.multiprocessing as _mp\n",
    "import pandas as pd\n",
    "from transformers import DistilBertTokenizer, DistilBertForSequenceClassification\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "import resnet_cifar10\n",
    "from tqdm import tqdm\n",
    "\n",
    "from networks import *\n",
    "from utils import *\n",
    "\n",
    "import copy\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1], [], []]\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "er = [[-1], [], []]\n",
    "print(er)\n",
    "print(not er[0])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RESNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntest_transform = transforms.Compose(\\n    [transforms.ToTensor(),\\n     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\\n\\ntest_set = datasets.CIFAR10(\"cifar10\", train=False, download=True, transform=test_transform)\\ntestloaders = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False)\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "test_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "test_set = datasets.CIFAR10(\"cifar10\", train=False, download=True, transform=test_transform)\n",
    "testloaders = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nmodel_type = \"20\"\\nmodels = []\\nens_num = [0, 301]\\nmodel_name =\"resnet\"+str(model_type)\\nmodels_path = \"resnet_models/\"\\n\\n# load all models\\nmodels = eval_model_load(model_type, ens_num, model_name, models_path)\\n\\nprint(\"Model Loaded\")\\nprint(\"Acc\", ens_evaluate_acc(models=models, testloaders=testloaders))\\n\\nmodels_time = []\\nfor i in range(5):\\n    models_time.append(ens_evaluate_acc(models=models, testloaders=testloaders, single=True, time_profiler=True)[-1])\\nprint(models_time)\\n'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model_type = \"20\"\n",
    "models = []\n",
    "ens_num = [0, 301]\n",
    "model_name =\"resnet\"+str(model_type)\n",
    "models_path = \"resnet_models/\"\n",
    "\n",
    "# load all models\n",
    "models = eval_model_load(model_type, ens_num, model_name, models_path)\n",
    "\n",
    "print(\"Model Loaded\")\n",
    "print(\"Acc\", ens_evaluate_acc(models=models, testloaders=testloaders))\n",
    "\n",
    "models_time = []\n",
    "for i in range(5):\n",
    "    models_time.append(ens_evaluate_acc(models=models, testloaders=testloaders, single=True, time_profiler=True)[-1])\n",
    "print(models_time)\n",
    "'''"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EfficientNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_transform = transforms.Compose(\n",
    "#     [transforms.Resize(224),\n",
    "#      transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "# test_set = datasets.CIFAR10(\"cifar10\", train=False, download=True, transform=test_transform)\n",
    "# testloaders = torch.utils.data.DataLoader(test_set, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from torchvision.models import efficientnet_b0, efficientnet_b1\n",
    "\n",
    "# model_type = 0\n",
    "# models = []\n",
    "# ens_num = [5, 7]\n",
    "\n",
    "# model_name =\"eb\"+str(model_type)\n",
    "# models_path = \"efficientnet_models/\"\n",
    "\n",
    "# # load all models\n",
    "# m = len(ens_num)\n",
    "# for i in range(m):   \n",
    "#     model_name_path = model_name +\"-\"+str(ens_num[i])\n",
    "#     if model_type==0:\n",
    "#         model = efficientnet_b0()\n",
    "#         model.classifier[1] = nn.Linear(1280, 10)\n",
    "#     if model_type==1:\n",
    "#         model = efficientnet_b1()\n",
    "#         model.classifier[1] = nn.Linear(1280, 10)\n",
    "#     print(\"LOAD\",models_path + model_name_path + \".pt\")\n",
    "#     model.load_state_dict(torch.load(models_path + model_name_path + \".pt\", map_location=device))\n",
    "#     model.eval()\n",
    "#     model.to(device)\n",
    "#     models.append(model)\n",
    "\n",
    "# print(\"Model Loaded\")\n",
    "# print(\"Acc\", ens_evaluate_acc(models, testloaders))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small (for MILR Benchmark)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_transform = transforms.Compose(\n",
    "#     [transforms.ToTensor(),\n",
    "#      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "# test_set = datasets.CIFAR10(\"cifar10\", train=False, download=True, transform=test_transform)\n",
    "# testloaders = torch.utils.data.DataLoader(test_set, batch_size=256, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model_type = \"smallmilr\"\n",
    "# models = []\n",
    "# ens_num = [0, 1]\n",
    "# model_name =\"vsmilr4-100\"\n",
    "# models_path = \"MILR/\"\n",
    "\n",
    "# # load all models\n",
    "# models = eval_model_load(model_type, ens_num, model_name, models_path)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DistilBert"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "''''''\n",
    "tokenizer = DistilBertTokenizer.from_pretrained(\"distilbert-base-uncased-finetuned-sst-2-english\")\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/Mohamed2519/Text-Classification-For-SST2-dataset/main/data/test.tsv\"\n",
    "df = pd.read_csv(url, delimiter='\\t', names=['labels','sentence'])\n",
    "\n",
    "encoded_data = tokenizer.batch_encode_plus(\n",
    "    df['sentence'].tolist(),\n",
    "    add_special_tokens=True,\n",
    "    max_length=128,\n",
    "    padding='max_length',\n",
    "    truncation=True,\n",
    "    return_attention_mask=True,\n",
    "    return_tensors='pt'\n",
    ")\n",
    "\n",
    "# Create TensorDataset from encoded_data\n",
    "dataset = TensorDataset(\n",
    "    encoded_data['input_ids'].to(device),\n",
    "    encoded_data['attention_mask'].to(device),\n",
    "    torch.tensor(df['labels'].tolist()).to(device)\n",
    ")\n",
    "\n",
    "# Create DataLoader from TensorDataset\n",
    "batch_size = 32\n",
    "testloaders = DataLoader(dataset, batch_size=batch_size, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LOAD distilbert_models/transformerDistilBert-7.pt\n",
      "LOAD distilbert_models/transformerDistilBert-12.pt\n",
      "Model Loaded\n",
      "Acc 0.9247666117517848\n",
      "TIME model 0: 15.01 ms\n",
      "TIME model 1: 8.24 ms\n",
      "TIME ALL: 23.25 ms\n",
      "TIME model 0: 6.57 ms\n",
      "TIME model 1: 8.12 ms\n",
      "TIME ALL: 14.69 ms\n",
      "TIME model 0: 9.69 ms\n",
      "TIME model 1: 8.58 ms\n",
      "TIME ALL: 18.27 ms\n",
      "TIME model 0: 7.91 ms\n",
      "TIME model 1: 6.05 ms\n",
      "TIME ALL: 13.96 ms\n",
      "TIME model 0: 6.02 ms\n",
      "TIME model 1: 7.59 ms\n",
      "TIME ALL: 13.61 ms\n",
      "[[15.012264251708984, 8.237361907958984, 23.24962615966797], [6.56890869140625, 8.124828338623047, 14.693737030029297], [9.693384170532227, 8.578777313232422, 18.27216148376465], [7.911443710327148, 6.047725677490234, 13.959169387817383], [6.01959228515625, 7.593870162963867, 13.613462448120117]]\n"
     ]
    }
   ],
   "source": [
    "''''''\n",
    "model_type = \"DistilBert\"\n",
    "models = []\n",
    "ens_num = [7, 12]\n",
    "model_name =\"transformer\"+str(model_type)\n",
    "models_path = \"distilbert_models/\"\n",
    "\n",
    "# load all models\n",
    "models = eval_model_load(model_type, ens_num, model_name, models_path)\n",
    "\n",
    "print(\"Model Loaded\")\n",
    "print(\"Acc\", ens_evaluate_acc(model_type=model_type, models=models, testloaders=testloaders))\n",
    "\n",
    "models_time = []\n",
    "for i in range(5):\n",
    "    models_time.append(ens_evaluate_acc(model_type=model_type, models=models, testloaders=testloaders, single=True, time_profiler=True)[-1])\n",
    "print(models_time)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GET THE SUM and DELTA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "deltas, summs = get_sum_delta(models)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model ready\n",
      "Acc 0.9247666117517848\n"
     ]
    }
   ],
   "source": [
    "modelDelta = NetDelta(models, ens_num, model_type, deltas, summs)\n",
    "modelDelta.to(device)\n",
    "modelDelta.eval()\n",
    "print(\"model ready\")\n",
    "print(\"Acc\", ens_evaluate_acc(model_type=model_type, wrappermodel=modelDelta, testloaders=testloaders))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(True)\n",
      "tensor(4.5628e-05)\n"
     ]
    }
   ],
   "source": [
    "x = torch.tensor(-0.04562711715698242)\n",
    "y = torch.tensor(-0.04562878608703613)\n",
    "print(torch.isclose(x,y, rtol=1e-4))\n",
    "print((1e-03 + 1e-08)*abs(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Profiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TIME model 0: 77.638 ms\n",
      "TIME model 1: 72.115 ms\n",
      "TIME ALL: 150.75 ms\n",
      "ORIGINAL\n",
      "0.9247666117517848\n",
      "TIME model 0: 77.627 ms\n",
      "TIME model 1: 74.145 ms\n",
      "TIME ALL: 152.77 ms\n",
      "==================\n",
      "\n",
      "BREAK 0\n",
      "0.9225700164744646\n",
      "==================\n",
      "\n",
      "FIXING 0\n",
      "TIME model 0: 46.072 ms\n",
      "TIME model 1: 74.193 ms\n",
      "TIME ALL: 120.27 ms\n",
      "recovering...bismillah\n",
      "TIME recovery: 2.497 ms\n"
     ]
    }
   ],
   "source": [
    "%colors nocolor\n",
    "\n",
    "times = []\n",
    "for k in range(1):\n",
    "    modelDelta.debug = False\n",
    "    modelDelta.use_sum = True\n",
    "    modelDelta.eval()\n",
    "    modelDelta = modelDelta.to(device)\n",
    "\n",
    "    # warmup\n",
    "    ens_evaluate_acc(model_type=model_type, wrappermodel=modelDelta, testloaders=testloaders)\n",
    "    ens_evaluate_acc(model_type=model_type, wrappermodel=modelDelta, testloaders=testloaders, single=True, time_profiler=True)\n",
    "\n",
    "    print(\"ORIGINAL\")\n",
    "    print(ens_evaluate_acc(model_type=model_type, wrappermodel=modelDelta, testloaders=testloaders)) \n",
    "    ens_evaluate_acc(model_type=model_type, wrappermodel=modelDelta, testloaders=testloaders, single=True, time_profiler=True)\n",
    "    print(\"==================\")\n",
    "\n",
    "    \n",
    "    modelDelta.debug = False\n",
    "    for t in range(1): # evaluate fixing time\n",
    "        print(f\"\\nBREAK {t}\")\n",
    "        modelDelta.use_sum = False\n",
    "        modelDelta.models[0] = flip(modelDelta.models[0], n=642, debug=False)\n",
    "        print(ens_evaluate_acc(model_type=model_type, wrappermodel=modelDelta, testloaders=testloaders))\n",
    "        print(\"==================\")\n",
    "\n",
    "        # FIXING\n",
    "        print(f\"\\nFIXING {t}\")\n",
    "        modelDelta.use_sum = True\n",
    "        modelDelta.skipper = True\n",
    "        modelDelta.debug = False\n",
    "        modelDelta.direct_recovery = False\n",
    "\n",
    "        _, _, times = ens_evaluate_acc(model_type=model_type, wrappermodel=modelDelta, testloaders=testloaders, single=True, time_profiler=True)\n",
    "        \n",
    "        modelDelta.recover_recent(time_profiler=True)\n",
    "        # print(ens_evaluate_acc(wrappermodel=modelDelta, testloaders=testloaders))\n",
    "\n",
    "        # while modelDelta.errors[0]!=-1:\n",
    "        #     print(modelDelta.errors)\n",
    "        \n",
    "        #     modelDelta.recover_recent()\n",
    "\n",
    "        #     modelDelta.debug = False\n",
    "        #     _, _, times = ens_evaluate_acc(wrappermodel=modelDelta, testloaders=testloaders, single=True, time_profiler=True)\n",
    "        #     # print(ens_evaluate_acc(wrappermodel=modelDelta, testloaders=testloaders))\n",
    "        #     print(\"==================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9231191652937946\n",
      "==================\n"
     ]
    }
   ],
   "source": [
    "modelDelta.debug = False\n",
    "print(ens_evaluate_acc(model_type=model_type, wrappermodel=modelDelta, testloaders=testloaders))\n",
    "print(\"==================\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "11938c6bc6919ae2720b4d5011047913343b08a43b18698fd82dedb0d4417594"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
